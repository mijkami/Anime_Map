{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c827f22",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "286d167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# Dataset\n",
    "\n",
    "dataset = pd.read_csv('../data/processed_data/active_users_df_10PlusRatings_partial.csv')\n",
    "anime_df = pd.read_csv('../data/raw_data/anime.csv')\n",
    "dataset = dataset.sort_values([\"user_id\", \"anime_id\"], ascending=(True, True))\n",
    "\n",
    "dataset.anime_id.nunique()\n",
    "\n",
    "dataset.user_id.nunique()\n",
    "\n",
    "anime_id_to_new_id = dict()\n",
    "id = 1\n",
    "\n",
    "for index, row in dataset.iterrows():\n",
    "    if anime_id_to_new_id.get(row['anime_id']) is None:\n",
    "        anime_id_to_new_id[row['anime_id']] = id\n",
    "        dataset.at[index, 'anime_id'] = id\n",
    "        id += 1\n",
    "    else:\n",
    "        dataset.at[index, 'anime_id'] = anime_id_to_new_id.get(row['anime_id'])\n",
    "\n",
    "\n",
    "# Need to map user ID to [1, user_num]\n",
    "user_id_to_new_id = dict()\n",
    "id = 1\n",
    "for index, row in dataset.iterrows():\n",
    "    if user_id_to_new_id.get(row['user_id']) is None:\n",
    "        user_id_to_new_id[row['user_id']] = id\n",
    "        dataset.at[index, 'user_id'] = id\n",
    "        id += 1\n",
    "    else:\n",
    "        dataset.at[index, 'user_id'] = user_id_to_new_id.get(row['user_id'])\n",
    "\n",
    "\n",
    "dataset.user_id\n",
    "\n",
    "num_users = len(dataset.user_id.unique())\n",
    "num_animes = len(dataset.anime_id.unique())\n",
    "train, test = train_test_split(dataset, test_size=0.2)\n",
    "\n",
    "print('Number of movies', num_animes)\n",
    "print('Number of users', num_users)\n",
    "\n",
    "# Order dataset by user_id and anime_id\n",
    "\n",
    "print('train shape: ', train.shape)\n",
    "print('test shape: ', test.shape)\n",
    "\n",
    "#train = train.reset_index()\n",
    "\n",
    "# 151519\n",
    "\n",
    "\n",
    "#train.anime_id.nunique()\n",
    "#num_animes\n",
    "\n",
    "#num_animes\n",
    "\n",
    "# GMF\n",
    "\n",
    "\n",
    "## Matrix factorisation\n",
    "\n",
    "import pydot\n",
    "import graphviz\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Flatten, Input, merge, concatenate\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "#from keras.utils.visualize_util import model_to_dot\n",
    "from IPython.display import SVG\n",
    "\n",
    "# Let's use a higher latent dimension.\n",
    "latent_dim = 10\n",
    "\n",
    "anime_input = Input(shape=[1],name='anime-input')\n",
    "anime_embedding = Embedding(num_animes + 1, latent_dim, name='anime-embedding')(anime_input)\n",
    "anime_vec = Flatten(name='anime-flatten')(anime_embedding)\n",
    "\n",
    "user_input = Input(shape=[1],name='user-input')\n",
    "user_embedding = Embedding(num_users + 1, latent_dim, name='user-embedding')(user_input)\n",
    "user_vec = Flatten(name='user-flatten')(user_embedding)\n",
    "from keras.layers import dot\n",
    "prod = dot([anime_vec, user_vec], axes=1, normalize=False)\n",
    "\n",
    "model = Model([user_input, anime_input], prod)\n",
    "model.compile('adam', 'mean_squared_error'\n",
    "              #,metrics=['mse']\n",
    "             )\n",
    "\n",
    "print('user_input',user_input.shape)\n",
    "print('anime_input',anime_input.shape)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "dataset.rating = dataset.rating.astype(float)\n",
    "\n",
    "dataset.dtypes\n",
    "\n",
    "train.user_id.shape\n",
    "\n",
    "train.anime_id.shape\n",
    "\n",
    "train.rating.shape\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "history = model.fit([train.user_id, train.anime_id], train.rating, epochs=4)\n",
    "\n",
    "pd.Series(history.history['loss']).plot(logy=True)\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Train Error\")\n",
    "plt.show()\n",
    "\n",
    "y_hat = np.round(model.predict([test.user_id, test.anime_id]), decimals=2)\n",
    "y_true = test.rating\n",
    "mean_absolute_error(y_true, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77952ec0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad0413d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anime_map",
   "language": "python",
   "name": "anime_map"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
