{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1d064e0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "846940ab",
   "metadata": {},
   "source": [
    "# imports\n",
    "\n",
    "## dependencies\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "\n",
    "\n",
    "import pydot\n",
    "import graphviz\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Flatten, Input, merge, concatenate, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "from keras.layers import dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#!pip install scikit-learn==0.24.2\n",
    "\n",
    "## files\n",
    "\n",
    "# model_path = \"../data/models_anime_map_knn_model.joblib\"\n",
    "# pickle.load(open('../model.sav', 'rb'))\n",
    "\n",
    "def get_anime():\n",
    "    anime_df_relevant_PG = pd.read_csv(\"../data/anime_df_relevant_PG.csv\")\n",
    "    return anime_df_relevant_PG.rename(columns={'MAL_ID' : 'anime_id'})\n",
    "\n",
    "def get_data():\n",
    "    data = pd.read_csv('../data/processed_data/active_users_df_10PlusRatings_partial.csv')\n",
    "    return data\n",
    "\n",
    "def get_model():\n",
    "    return pickle.load(open('../model.sav', 'rb'))\n",
    "\n",
    "get_model()\n",
    "\n",
    "def process_data():\n",
    "    data_users_df = get_data()\n",
    "    data_users_df['rating'] = data_users_df['rating']/10\n",
    "    \n",
    "    anime_df_relevant_PG = get_anime()\n",
    "    anime_name_df = anime_df_relevant_PG[['anime_id','Name']]\n",
    "    data_users_df_merge = data_users_df.merge(anime_name_df, on = 'anime_id', how='inner')\n",
    "    pivot_df = data_users_df_merge.pivot_table(index='anime_id',columns='user_id',values='rating').fillna(0)\n",
    "    \n",
    "    anime_Genres_df = anime_df_relevant_PG[['anime_id','Genres']]\n",
    "    anime_Genres_df_encoded = pd.concat(objs = [anime_Genres_df.drop(columns = 'Genres', axis =1), anime_Genres_df['Genres'].str.get_dummies(sep=\", \")], axis = 1)\n",
    "    anime_Genres_df_encoded = anime_Genres_df_encoded.set_index('anime_id')\n",
    "    \n",
    "    pivot_df = pivot_df.merge(anime_Genres_df_encoded, how='inner',left_index=True, right_index=True)\n",
    "    anime_name_pivot_df = data_users_df_merge[['anime_id','Name']].drop_duplicates()\n",
    "    anime_name_pivot_df = anime_name_pivot_df.sort_values('anime_id')\n",
    "    anime_name_pivot_df = anime_name_pivot_df.reset_index().drop(columns = 'index')\n",
    "    \n",
    "    return pivot_df, anime_name_pivot_df\n",
    "\n",
    "# predict\n",
    "\n",
    "def recomendation_10PlusRatings(anime_name, nb_recomendation = 10):\n",
    "    pivot_df, anime_name_pivot_df = process_data()\n",
    "    model = get_model()\n",
    "    index_nb = anime_name_pivot_df.index[anime_name_pivot_df['Name'] == anime_name].tolist()[0]\n",
    "    distances, indices = model.kneighbors(pivot_df.iloc[index_nb,:].values.reshape(1, -1), n_neighbors = nb_recomendation + 1)\n",
    "\n",
    "    prediction = []\n",
    "    for i in range(0, len(distances.flatten())):\n",
    "        if i == 0:\n",
    "            prediction.append([pivot_df.index[indices.flatten()[i]],0])\n",
    "        else:\n",
    "            prediction.append([pivot_df.index[indices.flatten()[i]],distances.flatten()[i]])\n",
    "    results = []\n",
    "    for i in range(len(prediction)):\n",
    "        anime_name = anime_name_pivot_df.query(f'anime_id == {prediction[i][0]}').iloc[0].Name\n",
    "        distance = prediction[i][1]\n",
    "        results.append([anime_name,distance])\n",
    "    return results\n",
    "\n",
    "predict = recomendation_10PlusRatings('Naruto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82ec423",
   "metadata": {},
   "source": [
    "# KNN + Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212c705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_data()\n",
    "dataset = dataset.sort_values([\"user_id\", \"anime_id\"], ascending=(True, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb7039b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anime_map",
   "language": "python",
   "name": "anime_map"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
