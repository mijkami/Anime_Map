{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c827f22",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "329ab65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1baace70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-31 10:49:19.486222: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-31 10:49:19.486271: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Flatten, Input, merge, concatenate, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "from keras.layers import dot\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "286d167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c802932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfd9bba",
   "metadata": {},
   "source": [
    "# KNN prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80fadda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "## dependencies\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "\n",
    "\n",
    "import pydot\n",
    "import graphviz\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Flatten, Input, merge, concatenate, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "from keras.layers import dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#!pip install scikit-learn==0.24.2\n",
    "\n",
    "## files\n",
    "\n",
    "# model_path = \"../data/models_anime_map_knn_model.joblib\"\n",
    "# pickle.load(open('../model.sav', 'rb'))\n",
    "\n",
    "def get_anime():\n",
    "    anime_df_relevant_PG = pd.read_csv(\"../data/anime_df_relevant_PG.csv\")\n",
    "    return anime_df_relevant_PG.rename(columns={'MAL_ID' : 'anime_id'})\n",
    "\n",
    "def get_data():\n",
    "    data = pd.read_csv('../data/processed_data/active_users_df_10PlusRatings_partial.csv')\n",
    "    return data\n",
    "\n",
    "def get_model():\n",
    "    return pickle.load(open('../model_knn.sav', 'rb'))\n",
    "\n",
    "get_model()\n",
    "\n",
    "def process_data():\n",
    "    data_users_df = get_data()\n",
    "    data_users_df['rating'] = data_users_df['rating']/10\n",
    "    \n",
    "    anime_df_relevant_PG = get_anime()\n",
    "    anime_name_df = anime_df_relevant_PG[['anime_id','Name']]\n",
    "    data_users_df_merge = data_users_df.merge(anime_name_df, on = 'anime_id', how='inner')\n",
    "    pivot_df = data_users_df_merge.pivot_table(index='anime_id',columns='user_id',values='rating').fillna(0)\n",
    "    \n",
    "    anime_Genres_df = anime_df_relevant_PG[['anime_id','Genres']]\n",
    "    anime_Genres_df_encoded = pd.concat(objs = [anime_Genres_df.drop(columns = 'Genres', axis =1), anime_Genres_df['Genres'].str.get_dummies(sep=\", \")], axis = 1)\n",
    "    anime_Genres_df_encoded = anime_Genres_df_encoded.set_index('anime_id')\n",
    "    \n",
    "    pivot_df = pivot_df.merge(anime_Genres_df_encoded, how='inner',left_index=True, right_index=True)\n",
    "    anime_name_pivot_df = data_users_df_merge[['anime_id','Name']].drop_duplicates()\n",
    "    anime_name_pivot_df = anime_name_pivot_df.sort_values('anime_id')\n",
    "    anime_name_pivot_df = anime_name_pivot_df.reset_index().drop(columns = 'index')\n",
    "    \n",
    "    return pivot_df, anime_name_pivot_df\n",
    "\n",
    "# predict\n",
    "\n",
    "def recomendation_10PlusRatings(anime_name, nb_recomendation = 10):\n",
    "    pivot_df, anime_name_pivot_df = process_data()\n",
    "    model = get_model()\n",
    "    index_nb = anime_name_pivot_df.index[anime_name_pivot_df['Name'] == anime_name].tolist()[0]\n",
    "    distances, indices = model.kneighbors(pivot_df.iloc[index_nb,:].values.reshape(1, -1), n_neighbors = nb_recomendation + 1)\n",
    "\n",
    "    prediction = []\n",
    "    for i in range(0, len(distances.flatten())):\n",
    "        if i == 0:\n",
    "            prediction.append([pivot_df.index[indices.flatten()[i]],0])\n",
    "        else:\n",
    "            prediction.append([pivot_df.index[indices.flatten()[i]],distances.flatten()[i]])\n",
    "    results = []\n",
    "    for i in range(len(prediction)):\n",
    "        anime_name = anime_name_pivot_df.query(f'anime_id == {prediction[i][0]}').iloc[0].Name\n",
    "        distance = prediction[i][1]\n",
    "        results.append([anime_name,distance])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa8e8c6",
   "metadata": {},
   "source": [
    "# Test dataset preparation before feeding to NeuMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2dc394",
   "metadata": {},
   "source": [
    " - concat lists of recom\n",
    " - remove duplicates\n",
    " - add user_id\n",
    " - map anime name and its number to feed to model\n",
    " - put in model\n",
    " - predict probable user ratings for predicted anime from knn\n",
    " - sort by desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eddc2224",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_recommend = pd.DataFrame(recomendation_10PlusRatings('Naruto'))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2299f7fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                               Naruto\n",
       "1                   Naruto: Shippuuden\n",
       "2                           Death Note\n",
       "3                               Bleach\n",
       "4                   Shingeki no Kyojin\n",
       "5     Fullmetal Alchemist: Brotherhood\n",
       "6      Code Geass: Hangyaku no Lelouch\n",
       "7                     Sword Art Online\n",
       "8                            One Piece\n",
       "9                           Fairy Tail\n",
       "10                       One Punch Man\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_recommend"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a2171",
   "metadata": {},
   "source": [
    "## Transorm list of recom into dataset suitable for NeuMF, column of user number(unique) and anime names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "907c01be",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_user_id = np.zeros(len(knn_recommend))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8266606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load anime dataset to map anime name from recom to its anime_id to feed to neuMF\n",
    "def get_anime(): \n",
    "    anime_df_relevant_PG = pd.read_csv(\"../data/anime_df_relevant_PG.csv\") \n",
    "    return anime_df_relevant_PG.rename(columns={'MAL_ID' : 'anime_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aac97a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.full(len(knn_recommend),fill_value = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6a8a4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b52162ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2781966839.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_5683/2781966839.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    test_to_neuMF =\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "test_df_to_neuMF = \n",
    "df3 = pd.DataFrame(test_to_neuMF, columns=['user_id', 'anime_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc787b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f76477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c5617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b21dc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model = tf.keras.models.load_model('../neuMFmodel.h5')\n",
    "    #model = joblib.load('neuMFmodel.joblib')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b94a8ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_neuMF = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748b8ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test,model):\n",
    "    y_pred = np.round(model.predict([test.user_id, test.anime_id]), decimals=2)\n",
    "    y_true = test.rating\n",
    "    mean_absolute_error(y_true, y_pred)\n",
    "    return y_true,y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anime_map",
   "language": "python",
   "name": "anime_map"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
