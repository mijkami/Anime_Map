{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c827f22",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "329ab65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot\n",
    "import graphviz\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1baace70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-09-01 11:27:46.373856: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-09-01 11:27:46.373994: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Flatten, Input, merge, concatenate, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "from keras.layers import dot\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "286d167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c802932",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcfd9bba",
   "metadata": {},
   "source": [
    "# Load KNN  and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80fadda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "## dependencies\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import pickle\n",
    "\n",
    "\n",
    "import pydot\n",
    "import graphviz\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Embedding, Flatten, Input, merge, concatenate, Dropout, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "from keras.layers import dot\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "#!pip install scikit-learn==0.24.2\n",
    "\n",
    "## files\n",
    "\n",
    "# model_path = \"../data/models_anime_map_knn_model.joblib\"\n",
    "# pickle.load(open('../model.sav', 'rb'))\n",
    "\n",
    "def get_anime():\n",
    "    anime_df_relevant_PG = pd.read_csv(\"../data/anime_df_relevant_PG.csv\")\n",
    "    return anime_df_relevant_PG.rename(columns={'MAL_ID' : 'anime_id'})\n",
    "\n",
    "def get_data():\n",
    "    data = pd.read_csv('../data/processed_data/active_users_df_10PlusRatings_partial.csv')\n",
    "    return data\n",
    "\n",
    "def get_model():\n",
    "    return pickle.load(open('../model_knn.sav', 'rb'))\n",
    "\n",
    "get_model()\n",
    "\n",
    "def process_data():\n",
    "    data_users_df = get_data()\n",
    "    data_users_df['rating'] = data_users_df['rating']/10\n",
    "    \n",
    "    anime_df_relevant_PG = get_anime()\n",
    "    anime_name_df = anime_df_relevant_PG[['anime_id','Name']]\n",
    "    data_users_df_merge = data_users_df.merge(anime_name_df, on = 'anime_id', how='inner')\n",
    "    pivot_df = data_users_df_merge.pivot_table(index='anime_id',columns='user_id',values='rating').fillna(0)\n",
    "    \n",
    "    anime_Genres_df = anime_df_relevant_PG[['anime_id','Genres']]\n",
    "    anime_Genres_df_encoded = pd.concat(objs = [anime_Genres_df.drop(columns = 'Genres', axis =1), anime_Genres_df['Genres'].str.get_dummies(sep=\", \")], axis = 1)\n",
    "    anime_Genres_df_encoded = anime_Genres_df_encoded.set_index('anime_id')\n",
    "    \n",
    "    pivot_df = pivot_df.merge(anime_Genres_df_encoded, how='inner',left_index=True, right_index=True)\n",
    "    anime_name_pivot_df = data_users_df_merge[['anime_id','Name']].drop_duplicates()\n",
    "    anime_name_pivot_df = anime_name_pivot_df.sort_values('anime_id')\n",
    "    anime_name_pivot_df = anime_name_pivot_df.reset_index().drop(columns = 'index')\n",
    "    \n",
    "    return pivot_df, anime_name_pivot_df\n",
    "\n",
    "# predict\n",
    "\n",
    "def recomendation_10PlusRatings(anime_name, nb_recomendation = 10):\n",
    "    pivot_df, anime_name_pivot_df = process_data()\n",
    "    model = get_model()\n",
    "    index_nb = anime_name_pivot_df.index[anime_name_pivot_df['Name'] == anime_name].tolist()[0]\n",
    "    distances, indices = model.kneighbors(pivot_df.iloc[index_nb,:].values.reshape(1, -1), n_neighbors = nb_recomendation + 1)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa8e8c6",
   "metadata": {},
   "source": [
    "# Test_df preparation before feeding to NeuMF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2dc394",
   "metadata": {},
   "source": [
    " - concat lists of recom\n",
    " - remove duplicates\n",
    " - add user_id\n",
    " - map anime name and its number to feed to model\n",
    " - put in model\n",
    " - predict probable user ratings for predicted anime from knn\n",
    " - sort by desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eddc2224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn_recommend = pd.DataFrame(recomendation_10PlusRatings('Naruto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eeb98769",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_recommend_id = recomendation_10PlusRatings('Naruto')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51a2171",
   "metadata": {},
   "source": [
    "## Transform list of recom into dataset suitable for NeuMF, column of user number(single number, because user is one person) and anime names they like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8266606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load anime dataset to map anime name from recom to its anime_id to feed to neuMF\n",
    "# def get_anime(): \n",
    "#     merged = pd.read_csv(\"../data/processed_data/merged_df_anime_users_relevant_PG.csv\") \n",
    "#     merged.drop(columns=['Genres',\"Studios\"])\n",
    "#     return merged\n",
    "#     #return anime_df_relevant_PG.rename(columns={'MAL_ID' : 'anime_id'})\n",
    "\n",
    "# merged = get_anime()\n",
    "\n",
    "# merged.drop(columns=['Genres','Studios','user_id','rating'],inplace = True)\n",
    "\n",
    "# merged.drop(columns=['user_id','rating'],inplace = True)\n",
    "\n",
    "# merged.head()\n",
    "\n",
    "# unique_names = merged.drop_duplicates('Name',keep='first')\n",
    "\n",
    "# unique_names.shape\n",
    "\n",
    "# #np.full(len(knn_recommend),fill_value = 0)\n",
    "# knn recommendations names to anime_ids\n",
    "\n",
    "# test_df_to_neuMF = \n",
    "# df3 = pd.DataFrame(test_to_neuMF, columns=['user_id', 'anime_id'])\n",
    "\n",
    "#unique_names.head()\n",
    "\n",
    "# knn_recommend\n",
    "\n",
    "# int(unique_names[unique_names.Name=='Trigun']['anime_id'])\n",
    "\n",
    "\n",
    "\n",
    "# #merged.anime_id.head()[merged[\"Name\"].head() == 'Cowboy Bebop']\n",
    "\n",
    "# recommend_anime_id = []\n",
    "# for i,j in enumerate(knn_recommend):\n",
    "#     id = int(unique_names[unique_names.Name==j]['anime_id'])\n",
    "#     recommend_anime_id.append(id)\n",
    "\n",
    "# recommend_anime_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c64ecf25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DONT NEED\n",
    "# Load anime_id full list\n",
    "# anime_list = pd.read_csv(\"../data/processed_data/anime_df_relevant_PG.csv\") \n",
    "\n",
    "# anime_list.rename(columns={'MAL_ID': 'anime_id'}, inplace=True)\n",
    "\n",
    "# anime_list.columns\n",
    "\n",
    "# anime_list.drop(columns=['Genres','Name','Studios'],inplace=True)\n",
    "\n",
    "# anime_id_list = anime_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66185831",
   "metadata": {},
   "source": [
    "## Create quasi user_id (perceptron requires it as input along with anime_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "015336c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#column_user_id = np.zeros(len(knn_recommend_id[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6be56997",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_user_id = [20 for i in range(len(knn_recommend_id[0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "640759e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8d883f44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  10, 1496, 1326,  237, 5564, 3251, 1362, 4990,   11, 3726, 6964])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_recommend_id[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1289277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(list(knn_recommend_id[0]), columns =['anime_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "067b626d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['user_id'] = column_user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ef992c6c",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1496</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1326</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>237</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5564</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3251</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1362</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4990</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3726</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>6964</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    anime_id  user_id\n",
       "0         10       20\n",
       "1       1496       20\n",
       "2       1326       20\n",
       "3        237       20\n",
       "4       5564       20\n",
       "5       3251       20\n",
       "6       1362       20\n",
       "7       4990       20\n",
       "8         11       20\n",
       "9       3726       20\n",
       "10      6964       20"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8964bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def id_transform(dataset):\n",
    "    anime_id_to_new_id = dict()\n",
    "    id = 1\n",
    "    for index, row in dataset.iterrows():\n",
    "        if anime_id_to_new_id.get(row['anime_id']) is None:\n",
    "            anime_id_to_new_id[row['anime_id']] = id\n",
    "            dataset.at[index, 'anime_id'] = id\n",
    "            id += 1\n",
    "        else:\n",
    "            dataset.at[index, 'anime_id'] = anime_id_to_new_id.get(row['anime_id'])\n",
    "    user_id_to_new_id = dict()\n",
    "    id = 1\n",
    "    for index, row in dataset.iterrows():\n",
    "        if user_id_to_new_id.get(row['user_id']) is None:\n",
    "            user_id_to_new_id[row['user_id']] = id\n",
    "            dataset.at[index, 'user_id'] = id\n",
    "            id += 1\n",
    "        else:\n",
    "            dataset.at[index, 'user_id'] = user_id_to_new_id.get(row['user_id'])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "72d39676",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = id_transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402b2598",
   "metadata": {},
   "source": [
    "# Load perceptron model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b21dc261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model = tf.keras.models.load_model('../neuMFmodel.h5')\n",
    "    #model = joblib.load('neuMFmodel.joblib')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b94a8ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_neuMF = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "748b8ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test,model):\n",
    "    y_pred = np.round(model.predict([test.user_id, test.anime_id]), decimals=2)\n",
    "#     y_true = test.rating\n",
    "#    mean_absolute_error(y_true, y_pred)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f1b6e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7eebee7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7.46],\n",
       "       [7.46],\n",
       "       [7.46],\n",
       "       [7.47],\n",
       "       [7.46],\n",
       "       [7.46],\n",
       "       [7.46],\n",
       "       [7.46],\n",
       "       [7.46],\n",
       "       [7.46],\n",
       "       [7.46]], dtype=float32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(test,model_neuMF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3644cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anime_map",
   "language": "python",
   "name": "anime_map"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "215px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
